---
title             : "TBD"
shorttitle        : "Entropy and Typing"

author: 
  - name          : "Matthew J. C. Crump"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Brooklyn College of CUNY, 2900 Bedford Avenue, Brooklyn, NY, 11210"
    email         : "mcrump@brooklyn.cuny.edu"
  - name          : "Walter Lai"
    affiliation   : "1"
  - name          : "Nicholaus Brosowsky"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Brooklyn College of the City University of New York"


author_note: |
  In this draft, listed authorship order simply indicates who is participating in the project

abstract: |
  Enter abstract here. Each new line herein must be indented, like this line.
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["r-references.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
mask              : no

class             : "man"
output            : papaja::apa6_pdf
---

```{r load_packages, include = FALSE}
library("papaja")
```

```{r analysis_preferences}
# Seed for random number generation
set.seed(42)
```

Hicks Law refers to the noticeable slowing of responses in choice reaction experiments when the
possible stimuli are less predictable.  

Hicks in his experiment, "On the rate of gain of information", tested his reaction speed on a choice reaction test.  During each trial he had to determine which of n lights was turned on.  He manipulated the set size n, and found that the greater the number of alternatives the slower his response.  His data also suggested that reaction speed is linearly related to the predictability of responses; Trials in which certain responses were disproportionately more likely ellicited faster response times than those in which each response was equally likely.

Hick's law at larger set sizes however does not have consistent experimental support.  

Conrad (1962) in an experiment which required subjects to name 320 nonsense syllables within trials of variable number of distinct syllables (number of alternatives) found that the response time was linearly correlated with the logarithm of number of alternatives.  However, Pierce and Karlin in 1957 
in an experiment which required subjects to read pages of words as quickly as possible, reported no differences in response times between trials with set sizes that ranged from 4 to 256 words.  
Proctor and Schneider in a review of studies testing Hick's Law attributes the inconsistency in large set size experiments to differences in skill level or practice between subjects and the arbitrariness of Stimulus Response coding/mappings when creating more number of alternatives.

Our experiment sought to test Hick's law on typing speeds.  

In this study, we used typing data from 346 typists to analyze the effect of letter uncertainty on response times.  In essence, every letter typed represents one choice reaction test trial from Hick's experiment.  In Hick's experiment, the probability of each light turning on was manipulated to change the H value.  This is analagous to the probability of certain letters appearing at a specific position in a word. Peter Norvig analyzed words from numerous texts and has determined the probability for each letter appearing at a specific position in 2 to 9 letter words.

For example, the first letter of a two letter long word is has a 9.44% chance to be an "a", 14.9% chance to be a "t", and a 25% chance to be an "i".  The third letter of a five letter long word is has a 13.5% chance as an "e", 4.91% chance as a "t", and a 11.4 % chance as a "a".  The H indices for each letter position - word length pair can be calculated.  The H for the 1st Letter, 2-letter-long word (abbreviated 1:2) is 2.85.  The H for the 3rd Letter, 5-letter-long word (abbreviated 3:5) is 3.94.  The differences in H tell us that 
the first letter of a two letter long word has lower uncertainty ie. it is more predictable than the third letter of a five letter long word.  

This combination of letter probabilities creates an H value for each unique pair of letter position and word length.  

One potential problem that can hinder our experiment's ability to test the Hick's Law is the fact that our typists vary in terms of their skill level.  This means that differences in RT between subjects will generate noise that may hide the H effect on RTs.
An advantage of testing Hick's Law with this data set is that the stimulus response coding is non-arbitrary.  The letters that typists see on the screen correspond exactly to the letters on their keyboards. 

# Methods


## Data analysis and pre-processing
We used `r cite_r("r-references.bib")` for all our analyses.

For each subject, we recorded timestamps for each keystroke using JavaScript. We applied the following pre-processing steps. We included IKSIs only for keystrokes involving a lower case letter, and only for correct keystrokes that were preceded by a correct keystroke. Outlier IKSIs were removed for each subject, on a cell-by-cell basis, using Van Selst & Jolicoeur's (1994) non-recursive moving criterion procedure, which eliminated approximately X% of IKSIs from further analysis.

# Results

## Typing Performance

```{r, echo=FALSE,messages=FALSE, warning=F}
library(knitr)
read_chunk('Entropy_typing_analysis.r')
```

```{r load_functions,messages=FALSE, warning=F}
```

```{r typing_mean_iksis_aov, messages=FALSE, warning=F}
```

For each subject, we calculated mean IKSIs as a function of letter position and word length. The letter position and word length factors were not factorially crossed. To determine whether there were differences among the means we submitted the means to a single factor repeated measures design with 45 levels (e.g., letter position|word length: 1|1, 1|2, 2|2, ... 9|9). Figure 1 shows mean IKSIs collapsed over subjects, as a function of letter position and word length.

```{r typing_mean_iksis_plot, messages=FALSE, warning=F}
```

The omnibus test indicated differences among the means were not likely due to chance, F (`r Exp1_ANOVA$df1`,`r Exp1_ANOVA$df2`) = `r Exp1_ANOVA$f`, MSE = `r Exp1_ANOVA$mse`, p < .001. Visual inspection of figure X shows several trends across the means consistent with first-letter slowing and mid-word slowing reported by Ostry (1983).

```{r typing_mean_iksis_comparisons, messages=FALSE, warning=F}
```

Our more important aim was to determine whether variation among these means can be explained by variation in letter uncertainty. For this reason we do not exhaustively discuss all of the possible 990 differences among these 45 conditions. Nevertheless, we did conduct all 990 comparisons using bonferroni corrected paired samples t-tests. The results are displayed Figure 2, which shows absolute mean differences between conditions color coded for significance (light grey is significant).

## Letter Uncertainty by position and word length

The primary question of interest was whether natural variation in letter uncertainty explains variance in mean IKSI by position and word length. We estimated letter uncertainty by position and word length from google's ngram database, which provides frequency counts of letters and words occuring in Google's massive corpus (X million) of digitized books. Letter frequency counts for letters a to z, for each position in words from length one to nine, were obtained from Norvig ().

For each letter frequency distribution, we computed Shannon's H (entropy) to quantify letter uncertainty. Shannon's H is defined as:

$H = -\sum p \log_2 p$

where, p is the probability of occurence for each letter in a given distribution. H is the number of bits needed to represent the distribution. We considered only the set of the 26 lowercase letters from a to z. For this set, H can range from 0 to ~4.7. H approaches 4.7 as letter probabilities approach a uniform distribution, indicating all letters are equiprobable, $H = -\sum \frac{1}{26} \log_2 \frac{1}{26} = 4.7004$. H by definition less than 4.7 for all unequal letter probability distributions, where some letters occur with higher/lower probabilities than others.

We converted each letter frequency distribution to a probability distribution then calculated H for each distribution. Figure 3 displays estimates of letter uncertainty (H) as a function of letter position and word length. Visual inspection of the graph shows that variation in letter uncertainty maps closely onto variation in mean IKSI (Figure 1) as a function of position and word length. In particular, letter uncertainty and mean IKSI for position one as a function of word length appear highly similar. And for the remaining positions, letter uncertainty shows an inverted U- shape with greater letter uncertainty in the middle rather than the beginning and endings of words. This suggests that natural variation of letter uncertainty across position and word in English may account for aspects of the first-letter and mid-word slowing phenomena in typing.



## Letter Uncertainty and Mean IKSI

If the Hick-Hyman law applied to continuous typing we would expect a neat linear relationship between mean IKSIs and letter uncertainty. Figure 4 shows a plot of mean IKSIs taken from all positions and word lengths against letter uncertainty. The scatterplot shows a general trend for mean IKSI to increase as a function of letter uncertainty.

```{r letter_uncertainty, messages=FALSE, warning=F}
```

```{r letter_uncertainty_by_IKSI, messages=FALSE, warning=F, fig.width=6.875}
```

A linear regression with group mean IKSIs (collapsed over subjects) as the dependent variable, and letter uncertainty as the independent variable showed a significant positive trend, F(`r lr_results$fstatistic[2]`, `r lr_results$fstatistic[3]`) = `r lr_results$fstatistic[1]`, p = `r sprintf(as.character(signif(lr_results$coefficients[2,4],digits=2)))`, $R^2 =$ `r  lr_results$r.squared` ( meanIKSI =  `r lr_results$coefficients[1,1]` $+$ `r lr_results$coefficients[2,1]` $* H$ ). We also conducted separate linear regressions for each subject and found similar results. For example, the mean correlation was r = `r skim_out$numeric$mean[2]` (SE = `r skim_out$numeric$SE[2]`); mean $R^2$ = `r skim_out$numeric$mean[3]` (SE = `r skim_out$numeric$SE[3]`); and mean p = `r skim_out$numeric$mean[1]` (SE = `r skim_out$numeric$SE[1]`).

## Interim Discussion

```{r letter_uncertainty_by_IKSI_dual, messages=FALSE, warning=F}
```

We can conclude that letter uncertainty as a function of position and length explains a small amount variation in mean IKSIs during continuous typing. The present analysis does not provide strong evidence that a process sensitive to letter uncertainty causes both first-letter and mid-word slowing. For example, all of the first position mean IKSIs are longer than mean IKSIs for other positions at comparables levels of letter uncertainty. And, a linear regression on the group mean IKSIs including letter uncertainty and position (first letter vs. other letter) as independent variables explains much more variance, $R^2$ = `r  lr_results_dual$r.squared`, p < .001, than the regression only including letter uncertainty.

This pattern invites a dual-process interpretation. For example, first-letter slowing could be explained by a planning process that increases first position IKSIs as a function of word length. Longer words have more letters, thus plan construction and buffering is assumed to take more time before sequence production begins. At the same time, the finding that letter uncertainty does explain some variance in mean IKSI across position suggests that sequence production is also influenced by a process sensitive to letter uncertainty.

## Letter Uncertainty by position, word length, and n-1 letter identity

Determining whether first-letter and mid-word slowing could emerge from a process sensitive to letter uncertainty depends on how letter uncertainty is calculated. Letter uncertainty can be calculated from any discrete probability distribution of letters. In the previous section we somewhat arbitrarily calculated letter uncertainty separately for each letter position in words of length one to nine. However, the number of alternative schemes is vast. For example, we could further conditionalize our postion by word length probability distributions by the letter identities of letters occuring in any position n-1 to n-x, or n+1 to n+y of a specific position. Furthermore, we could conditionalize letter distributions upon any permissible number of preceding or succeeding n-grams (groups of letters). 


Although an exhaustive calculation of letter uncertainty is beyond the scope of this paper, we nevertheless took one further step and calculated letter uncertainty by position and word length, conditionalizing upon n-1 letter identity. Fortunately, Norvig () also provided bigram frequency counts from the google ngram corpus as a function of position and word length. We calculated letter uncertainty in the following manner. First position letters have no preceding letter, so H as a function of word length was identical to our prior calculation. For letters in positions two to nine, for all word lengths, we calculated H for every n-1 letter identity, and then took the mean H for each position and length. For example, the second position of a two-letter word has a maximum of 26 letter probability distributions, one for each possible n-1 letter (a to z). We calculated H for all n-1 distributions, then took the mean H as our measure of letter uncertainty for each position and word length. Figure X shows mean H conditionalized by n-1 letter identity, as a function of letter position and word length.

```{r letter_uncertainty_bigram, messages=FALSE, warning=F,fig.width=6.875}
```


Unsurprisingly, letter identity becomes more predictable when n-1 letter identity is known. Compared to the letter uncertainty measures in Figure X, we see that H for letters in positions two to nine is much lower when n-1 letter identity is taken into account. More important, the pattern of H in Figure X much more closely resembles the pattern of mean IKSIs in Figure X.

Figure X displays a scatterplot of mean IKSIs as a function of letter uncertainty conditionalized by letter n-1 identity across positions and word length. A linear regression on mean IKSIs using our new measure of letter uncertainty as the independent variable showed a strong positive relationship, F(`r lr_results_bigram$fstatistic[2]`, `r lr_results_bigram$fstatistic[3]`) = `r lr_results_bigram$fstatistic[1]`, p = `r sprintf(as.character(signif(lr_results_bigram$coefficients[2,4],digits=2)))`, $R^2 =$ `r  lr_results_bigram$r.squared` ( meanIKSI =  `r lr_results_bigram$coefficients[1,1]` $+$ `r lr_results_bigram$coefficients[2,1]` $* H$ ).

# Discussion

# An instance-based model

We have shown that variation in mean IKSIs as a function of letter position and word length can be well explained by natural variation in letter uncertainty conditionalized by letter n-1 identity by letter position and word length. This finding licenses consideration of the claim that first-letter and mid-word slowing are caused by a single process sensitive to letter uncertainty. However, the plausibility of this causal claim is empty in the absence of a working process model. Next, we establish theoretical plausibility by showing that letter uncertainty influences on performance can be explained in terms of Logan's (1988) instance-based memory model of automatization.

Instance theory provides an account of how performance becomes automatized with practice. Among other things, it provides a theoretical explanation of learning curves that follow a power function (). We will show that the instance theory process also develops sensitivity to uncertainty in the stimuli it encounters over practice. More specifically, instance theories predictions for performance are nearly identical to the hick-hyman law which posits that reaction times are a linear function of the uncertainty in a choice set.

Instance theory models learning as a function of practice in terms of cue-driven retrieval of stored memory traces. A new unique trace is preserved in memory every time a response is given to a stimulus. When a familiar stimulus is encountered again, it automatically triggers the retrieval of all stored instances of the stimulus. The timing of the memory-based response to a current stimulus is treated as a race. Whichever memory trace is retrieved first wins the race. As a result, the memory-based reaction time to respond to a stimulus is determined by the retrieval time associated with the fastest memory trace for that stimulus. The retrieval times for every memory trace are assumed to vary, and can be sampled from any desired distribution.

So, instance theory models practice based performance speed-ups in terms of sampling extreme values from a growing retrieval time distribution. As the number of memory traces grows the range of the retrieval time distribution also grows. As a result, the minimum value of the distribution (fastest retrieval) is more likely to be smaller for distributions with more than fewer memory traces. In other words, reaction times will tend to be faster for higher than lower frequency stimuli.

We can now draw a more transparent connection between instance theory and information theory. Information theory provides H as a summary statistic of probability distributions for any discrete set of stimuli. Empirical probability distributions for natural occuring stimuli, such as letters, are found by counting stimulus frequencies, and then dividing a stimulus frequency distribution by it's sum. Instance theories predictions for response times in a stimulus set will be monotonically decreasing as a function of each stimulus frequencies. We should also expect that a summary statistic of instance theories predictions for mean reaction time, collapsing across all items in the set, will behave in a similar manner to information theory's summary statistic, which also collapses over the expected frequency of each item in the set. We demonstrate these relationships by monte-carlo simulation.

Our goal was to model instance theory predictions for keystroke production times for typing natural english sentences as a function of letter position and word length. We treated all 26 letters that could possibly occur in any position for any word length as completely unique and independent stimuli. We modeled the structure of natural english using the 45 letter probability distributions derived from Norvig's letter frequence counts by position and word length, from Google's n-gram corpus.

We modelled keystroke times for specific letters in the following manner. At different practice intervals each letter, occuring in each position for each word length, had occured in the model's history with specific frequency. We estimated reaction time as a function of frequency by monte-carlo simulation. We assumed that the retrieval time distribution for each stimulus was sampled from a normal distribution with mean = 500, and standard deviation = 100. Using R, we sampled retrieval times from the normal distribution n times, where n was the current number of memory traces. Then we took the minimum value from the sampling distribution as the reaction time. We repeated this process 1000 times to estimate the expected mean reaction time (expected minimum retrieval time) for the given frequency value. In this way, we estimated mean keystroke production times for every letter position across different word lengths. Last, we evaluated model predictions across four practice intervals.

Figure X displays the instance model predictions, across increasing amounts of practice, for mean keystroke production times as a function of letter position and word length. As expected, simulated keystroke times shorten with practice. More imporant, at each stage in practice, simulated keystroke times show the same qualitative pattern of variation across letter postion and word length. Notably, these appear very similar to human typing performance, and to letter uncertainty as a function of position and word length.

Finally, we conducted linear regressions on simulated mean typing times using letter uncertainty as the independent variable. We found that letter uncertainty nearly perfectly explains the variance in simulated keystroke time, with R^2 increasing across practice. 




# Conclusion

Future studies should investigate the role of probability of repetition in regulating response times.  
Kornblum in 1969 found that with constant H, trials that had higher chances of sequentially repeating stimuli experienced faster response times.  


\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
